{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import models\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "path = 'C:/Users/akshg/Desktop/Emotion CNN/'\n",
    "data = pd.read_csv('icml_face_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'surprise' and 'disgust' labels\n",
    "data = data[(data['emotion'] != 5) & (data['emotion'] != 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update emotions dictionary\n",
    "emotions = {0: 'Angry', 1: 'Fear', 2: 'Happy', 3: 'Sad', 4: 'Neutral'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare data\n",
    "def prepare_data(data):\n",
    "    image_array = np.zeros(shape=(len(data), 48, 48))\n",
    "    image_label = np.array(list(map(int, data['emotion'])))\n",
    "    for i, row in enumerate(data.index):\n",
    "        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n",
    "        image = np.reshape(image, (48, 48))\n",
    "        image_array[i] = image\n",
    "    return image_array, image_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data splits\n",
    "train_image_array, train_image_label = prepare_data(data[data[' Usage']=='Training'])\n",
    "val_image_array, val_image_label = prepare_data(data[data[' Usage']=='PrivateTest'])\n",
    "test_image_array, test_image_label = prepare_data(data[data[' Usage']=='PublicTest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "train_images = train_image_array.reshape((train_image_array.shape[0], 48, 48, 1)).astype('float32') / 255\n",
    "val_images = val_image_array.reshape((val_image_array.shape[0], 48, 48, 1)).astype('float32') / 255\n",
    "test_images = test_image_array.reshape((test_image_array.shape[0], 48, 48, 1)).astype('float32') / 255\n",
    "\n",
    "# Remove labels for 'surprise' and 'disgust'\n",
    "train_labels = to_categorical(train_image_label, num_classes=7)[:, [0, 2, 3, 4, 6]]\n",
    "val_labels = to_categorical(val_image_label, num_classes=7)[:, [0, 2, 3, 4, 6]]\n",
    "test_labels = to_categorical(test_image_label, num_classes=7)[:, [0, 2, 3, 4, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model\n",
    "model = models.Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)),\n",
    "    MaxPool2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPool2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(5, activation='softmax')  # Updated to 5 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    validation_data=(val_images, val_labels),\n",
    "                    epochs=15,\n",
    "                    batch_size=32)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training/validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training/validation accuracy\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_labels = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison of distributions\n",
    "def plot_distribution_comparison(true_labels, pred_labels, title1='', title2=''):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=False)\n",
    "    x = emotions.values()\n",
    "    \n",
    "    true_counts = pd.Series(true_labels.argmax(axis=1)).value_counts().sort_index()\n",
    "    pred_counts = pd.Series(pred_labels.argmax(axis=1)).value_counts().sort_index()\n",
    "    \n",
    "    axs[0].bar(x, true_counts, color='orange', label='True Distribution')\n",
    "    axs[0].set_title(title1)\n",
    "    axs[0].legend()\n",
    "    \n",
    "    axs[1].bar(x, pred_counts, label='Predicted Distribution')\n",
    "    axs[1].set_title(title2)\n",
    "    axs[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison of true and predicted distributions for train and validation sets\n",
    "plot_distribution_comparison(train_labels, val_labels, title1='True Train Distribution', title2='Predicted Train Distribution')\n",
    "plot_distribution_comparison(test_labels, pred_test_labels, title1='True Test Distribution', title2='Predicted Test Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Define hyperparameters grid\n",
    "# param_grid = {\n",
    "#     'learning_rate': [0.001, 0.01, 0.1],\n",
    "#     'batch_size': [32, 64, 128],\n",
    "#     'epochs': [10, 15, 20]\n",
    "# }\n",
    "\n",
    "# # Create KerasClassifier wrapper for use with GridSearchCV\n",
    "# model = KerasClassifier(build_fn=create_model)\n",
    "\n",
    "# # Perform grid search\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=1)\n",
    "# grid_result = grid.fit(train_images, train_labels)\n",
    "\n",
    "# # Summarize results\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Load pre-trained VGG16 model without top layers (include_top=False)\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification layers on top of VGG16\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(5, activation='softmax')(x)  # Output layer with 5 classes\n",
    "\n",
    "# Combine base model with custom layers\n",
    "model_vgg16 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model_vgg16.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_vgg16 = model_vgg16.fit(train_images, train_labels,\n",
    "                                validation_data=(val_images, val_labels),\n",
    "                                epochs=15,\n",
    "                                batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss_vgg16, test_acc_vgg16 = model_vgg16.evaluate(test_images, test_labels)\n",
    "print('VGG16 Test accuracy:', test_acc_vgg16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "\n",
    "# Load pre-trained ResNet50 model without top layers (include_top=False)\n",
    "base_model_resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model_resnet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification layers on top of ResNet50\n",
    "x_resnet = base_model_resnet.output\n",
    "x_resnet = Flatten()(x_resnet)\n",
    "x_resnet = Dense(256, activation='relu')(x_resnet)\n",
    "predictions_resnet = Dense(5, activation='softmax')(x_resnet)  # Output layer with 5 classes\n",
    "\n",
    "# Combine base model with custom layers\n",
    "model_resnet = Model(inputs=base_model_resnet.input, outputs=predictions_resnet)\n",
    "\n",
    "# Compile the model\n",
    "model_resnet.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_resnet = model_resnet.fit(train_images, train_labels,\n",
    "                                  validation_data=(val_images, val_labels),\n",
    "                                  epochs=15,\n",
    "                                  batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss_resnet, test_acc_resnet = model_resnet.evaluate(test_images, test_labels)\n",
    "print('ResNet Test accuracy:', test_acc_resnet)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
